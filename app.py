import streamlit as st
import openai
from feedback_logic import generate_feedback
import pytesseract
from PIL import Image
from surya.ocr import run_ocr
from surya.model.detection.model import load_model as load_det_model, load_processor as load_det_processor
from surya.model.recognition.model import load_model as load_rec_model
from surya.model.recognition.processor import load_processor as load_rec_processor

image = Image.open(IMAGE_PATH)
langs = ["en"] # Replace with your languages - optional but recommended
det_processor, det_model = load_det_processor(), load_det_model()
rec_model, rec_processor = load_rec_model(), load_rec_processor()

predictions = run_ocr([image], [langs], det_model, det_processor, rec_model, rec_processor)

# OpenAI API ì„¤ì •
openai.api_key = st.secrets["OPENAI_API_KEY"]




# Streamlit ê¸°ë³¸ êµ¬ì„±
st.set_page_config(page_title="Math Feedback Service", layout="wide")
st.title("ì´ˆë“±í•™êµ ìˆ˜í•™ ë¬¸ì œ í”¼ë“œë°± ì„œë¹„ìŠ¤")

# ìƒíƒœ ì´ˆê¸°í™”
if "additional_info_visible" not in st.session_state:
    st.session_state["additional_info_visible"] = False
if "additional_info_content" not in st.session_state:
    st.session_state["additional_info_content"] = ""
if "camera_mode" not in st.session_state:
    st.session_state["camera_mode"] = False  # ì¹´ë©”ë¼ ëª¨ë“œ í™œì„±í™” ìƒíƒœ

# ë¬¸ì œ ì…ë ¥ ì˜ì—­
problem = st.text_area("ìˆ˜í•™ ë¬¸ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: ì§ê°ì‚¼ê°í˜• ëª¨ì–‘ì˜ ì¢…ì´ë¥¼ ëŒë ¤ ì›ë¿”ì„ ë§Œë“¤ì—ˆì„ ë•Œ...")

# í”¼ë“œë°± ìš”ì²­ ë²„íŠ¼
if st.button("í”¼ë“œë°± ìƒì„±"):
    if problem.strip():
        with st.spinner("í”¼ë“œë°±ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            feedback, requires_more_info = generate_feedback(problem)

            if requires_more_info:
                st.warning("ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì•„ë˜ì— ì¶”ê°€ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                st.session_state["additional_info_visible"] = True
            else:
                st.subheader("ìƒì„±ëœ í”¼ë“œë°±:")
                st.markdown(feedback)
    else:
        st.warning("ë¬¸ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")

# ì¶”ê°€ ì •ë³´ ì…ë ¥ ì˜ì—­ (ìƒíƒœ ê¸°ë°˜ìœ¼ë¡œ í‘œì‹œ)
if st.session_state["additional_info_visible"]:
    additional_info = st.text_area(
        "ë¬¸ì œì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
        value=st.session_state["additional_info_content"],  # ìœ ì§€ëœ ê°’ì„ ì‚¬ìš©
        key="additional_info_input"
    )

    # ìƒíƒœ ì—…ë°ì´íŠ¸ ë²„íŠ¼ í´ë¦­ ì‹œ ì €ì¥
    if st.button("ì¶”ê°€ ì •ë³´ë¥¼ í¬í•¨í•œ í”¼ë“œë°± ìƒì„±"):
        st.session_state["additional_info_content"] = additional_info  # ì…ë ¥ëœ ê°’ì„ ìƒíƒœì— ì €ì¥
        combined_input = f"ë¬¸ì œ: {problem}\nì¶”ê°€ ì •ë³´: {st.session_state['additional_info_content']}"
        with st.spinner("í”¼ë“œë°±ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            feedback, _ = generate_feedback(combined_input)
            st.subheader("ìƒì„±ëœ í”¼ë“œë°±:")
            st.markdown(feedback)

# ì¹´ë©”ë¼ ì…ë ¥ ì˜ì—­
camera_button_label = "ğŸ“·"
langs = ["ko"] # Replace with your languages - optional but recommended
det_processor, det_model = load_det_processor(), load_det_model()
rec_model, rec_processor = load_rec_model(), load_rec_processor()

if st.button(camera_button_label):
    if not st.session_state["camera_mode"]:
        st.session_state["camera_mode"] = True  # ì¹´ë©”ë¼ ëª¨ë“œ í™œì„±í™”
    else:
        st.session_state["camera_mode"] = False  # ì´¬ì˜ ì™„ë£Œ í›„ ë¹„í™œì„±í™”

if st.session_state["camera_mode"]:
    image = st.camera_input("ì¹´ë©”ë¼ë¡œ ë¬¸ì œë¥¼ ìº¡ì²˜í•˜ì„¸ìš”")
    if image:
        predictions = run_ocr([image], [langs], det_model, det_processor, rec_model, rec_processor)

        st.text_area("ì¶”ì¶œëœ í…ìŠ¤íŠ¸:", value=predictions, height=200)
    else:
        st.warning("ì´ë¯¸ì§€ë¥¼ ìº¡ì²˜í•´ì£¼ì„¸ìš”!")



